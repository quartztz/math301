\chapter{Rings and fields}

\marginpar{Week 8}
\section{One to rule them all}

\begin{definition}
  A \emph{ring} is a set $A$ with two operations defined on it: $+$ and $\cdot$, in such a way that
  \begin{enumerate}
    \item $A$ is an abelian group with respect to $+$, containing a neutral element $0$. 
    \item $\cdot$ is associative: $(a \cdot b) \cdot c = a \cdot (b \cdot c)$, et il $\exists 1 \in A: 1 \cdot a = a \cdot 1$.
    \item  $\cdot$ is both left- and right-distributive over $+$: $a \cdot (b + c) = ab + ac,  (a + b) \cdot c = ac + bc$. 
  \end{enumerate}
\end{definition}
\aparte{Examples}{
  Let us consider some examples: 
  \begin{itemize}
    \item $\mathbb{Z}: \gen{+, \cdot, 0, 1}$ is a ring! Though it doesn't contain any multiplicative inverses, it fits the definitions nicely. 
    \item $A = \mathbb{Z}[\sqrt{2}] := \{a + b\sqrt{2}, a, b \in \mathbb{Z}\}$ contains 0 and 1. Additionally: 
    \begin{gather*}
      (a + b\sqrt{2}) + (c + d \sqrt{2}) = (a + c) + (b + d)\sqrt{2} \in A\\
      -a - b\sqrt{2} \in A \\
      (a + b\sqrt{2})(c + d\sqrt{2}) = ac + 2bd + \sqrt{2}(ad + bc) \in A \\
    \end{gather*}
    \item $\mathbb{Q}[\sqrt{2}]$ is a ring. Proof of this is left as an exercice to the reader. 
  \end{itemize}
}

In this course, we will consider only \emph{commutative rings}, such that $ab = ba \forall a, b \in A$. 

\begin{definition}\label{zerodiv-def}
  $a \in A$ is a \emph{zero divisor} if there exists an $0 \neq x \in A$ such that $ax = 0$. 
\end{definition}
Most rings we are used to do not have any nontrivial zero divisors. Let us consider another one: 
\aparte{Example}{
  Consider: 
  \[
    \mathbb{Z}/n\mathbb{Z} = \{[0], [1], ..., [n - 1]\}
  \]
  It is isomorphic to the cyclic group of order $n$, meaning it is an abelian group with respect to addition. $\cdot$ is associative, and $[1]$ is its neutral element wrt multiplication. 

  Consider now an element $[a] \in \mathbb{Z}/n\mathbb{Z}$. 
  \begin{itemize}
    \item If $\gcd(a, n) = d > 1$, then we can write \[[a] \cdot \left[\frac{n}{d}\right] = [1]\] meaning that $a$ is a nontrivial zero divisor of the ring. 
    \item If $a, n$ are coprime, then by Bezout's theorem 
    \begin{gather*}
      \exists x, y : ax + ny = 1 \Rightarrow [a][x] = [1] \Rightarrow [a]^{-1} = [x]
    \end{gather*}
    Additionally, if we consider $[b]: [b] \cdot [a] = 0$, then we have
    \[
      [b] \cdot [a] = [0] \Rightarrow [b] \cdot [a] \cdot [x] = [0] \Rightarrow [b] \cdot [1] = [0] \Rightarrow [b] = [0]
    \]
    Meaning that $[a]$ cannot be a zero divisor of the ring. 
  \end{itemize}
  This means that an element of $\mathbb{Z}/n\mathbb{Z}$ is either invertible, or a zero divisor. 
}

\begin{definition}
  A ring that has no nontrivial zero divisors is called an \emph{integral domain}.
\end{definition}
\begin{definition}
  A commutative ring where all nonzero elements have a multiplicative inverse is called a \emph{field}. $\forall 0 \neq a \in A \exists a^{-1} \in A : a a^{-1} = a^{-1} a = 1$
\end{definition}
\begin{corollary}
  $\mathbb{Z}/n\mathbb{Z}$ either has nontrivial zero divisors ($\Leftrightarrow n$ is not prime) or it is a field and an integral domain ($\Leftrightarrow n = p$ for some prime $p$). 
\end{corollary}
\begin{proof}
  If it has no nontrivial zero divisors, that means that there is no $[a] \in \{[1], ..., [n - 1]\}$ such that $\gcd(a, n) > 1$. Therefore, $n$ has no divisors other than itself and 1, and it must be a prime $p$ by definition. If that's the case, then $\forall [b] \neq 0, \gcd(b, p) = 1 \Rightarrow [b]$ has a multiplicative inverse, meaning that $\mathbb{Z}/n\mathbb{Z}$ is a field.
\end{proof}

\begin{theorem*}
  A field is an integral domain. An invertible element is not a zero divisor. 
\end{theorem*}
\begin{proof}
  Suppose $ab = 0$ in a field $A$ such that $a \neq 0$. This means that there exists a $a^{-1} \in A$ such that $aa^{-1} = 1$. This means that :
  \begin{align}
    ab = 0 
    &\Leftrightarrow a^{-1}ab = a^{-1} \cdot 0 \\
    &\Leftrightarrow 1 \cdot b = 0 \\
    &\Leftrightarrow b = 0
  \end{align}
  meaning $a$ cannot be a zero divisor. This means that if all non-zero elements in $A$ are invertible, then $A$ cannot have nontrivial zero divisors. This is equivalent to saying that if $A$ is a field, then it is an integral domain, proving our proposition.
\end{proof}
\aparte{Remark}{The converse isn't true! $\mathbb{Z}$ is an integral domain, but $2 \in \mathbb{Z}$ does not have a multiplicative inverse.}

This allows the following characterization: 
\[
  \text{Fields} \subset \text{Integral Domains} \subset \text{Commutative Rings}
\]
And for the following statements on $\mathbb{Z}/n\mathbb{Z}$ : 
\[
  \mathbb{Z}/n\mathbb{Z} \text{ integral domain} \Leftrightarrow \mathbb{Z}/n\mathbb{Z} \text{ field} \Leftrightarrow n = p \text{ prime}
\]

\section{Less than ideal}

\begin{definition}
  Let $A$ be a commutative ring. $I \subset A$ is an \emph{ideal} if it has the following properties:
  \begin{itemize}
    \item it is a subgroup with respect to +, i.e: it contains 0, $-a$ for any $a \in I$, and it is closed wrt +. 
    \item $\forall x \in A, a \in I: x \cdot a \in I$. 
  \end{itemize}
\end{definition}
\aparte{Examples}{
  Let's have a look at some examples
  \begin{itemize}
    \item $\{0\} \subset A, A \subset A$ are ideals for any commutative ring $A$. That is not very interesting.
    \item Consider $\mathbb{Z}$. Then, $2\mathbb{Z} = \{2a, a \in \mathbb{Z}\}$ is an ideal! It's easy to verify it is a subgroup for $+$, and we have that, for any $x \in \mathbb{Z}, 2a \cdot x \in 2\mathbb{Z}$. This is true for any $d \in \mathbb{Z}$. 
  \end{itemize}
}

\begin{definition}
  We say that an ideal $I \subset A$ is \emph{proper} if $I \neq A$, and \emph {nontrivial} if $I \neq 0$. 
\end{definition}
\aparte{Properties}{
  Let $I, J \subset A$ two ideals. Then: 
  \begin{enumerate}
    \item[(i)] if $1 \in I$, then $I = A$. 
    
    \textit{This is due to the properties of ideals: $\forall x \in A, 1 \cdot x \in I \Rightarrow x \in I \Rightarrow I = A$}
    
    \item[(ii)] $I \cap J$ is an ideal

    \textit{Again, easy to verify applying properties of ideals: let $x, y \in I \cap J$.}
    \begin{gather*}
      x + y \in I, J \Rightarrow x + y \in I \cap J \\
      -x \in I, J \Rightarrow -x \in I \cap J \\
      0 \in I, J \Rightarrow 0 \in I \cap J
    \end{gather*}
    \textit{Meaning it is a subgroup. Also, for any $a \in A$, we have that $ax \in I, ax \in J$, which means $ax \in I \cap J$. This makes it an ideal!}

    \item[(iii)] $I + J = \{i + j\}_{i \in I, j \in J}$ is an ideal.

    \item[(iv)] $I \cdot J = \{\sum_{i = 1}^k x_i y_i\}_{x_i \in I, y_i \in J}$ is an ideal.\footnotemark

    \item[(v)] $I \cup J$ is not necessarily an ideal

    \textit{More often than not, it is not an additive subgroup: consider $I = 2\mathbb{Z}$, $J = 3\mathbb{Z}$}
  \end{enumerate}
}
\footnotetext{Proofs to (iii) and (iv) are left as exercice to the reader, as they are similar to that of (ii).}

We can verify some fun properties on integer ideals. Let $A = \mathbb{Z}, I = 6\mathbb{Z}, J = 10\mathbb{Z}$. Then: 
\begin{itemize}
  \item \textbf{Intersection:} We have: 
  \begin{align*}
    I \cap J 
    &= \{z \in \mathbb{Z}: z = 6n \land z = 10m, n, m \in \mathbb{Z}\} \\
    &= \{\text{common multiples of 6 and 10}\} \\
    &= \{\text{all multiples of} \lcm(6, 10) = 30\} \\
    &= 30\mathbb{Z}
  \end{align*}
  \item \textbf{Addition:} We have: 
  \begin{align*}
    I + J 
    &= \{6n + 10m\}_{n, m \in \mathbb{Z}} \\
    &= \{\gcd(6, 10)k, k \in \mathbb{Z}\} \tag*{\text{[By Bezout]}} \\
    &= 2\mathbb{Z}
  \end{align*}
  \item \textbf{Product:} We have: 
  \begin{align*}
    I \cdot J 
    &= \left\{\sum_{i = 1}^k 6x_i \cdot 10y_i, x_i, y_i \in \mathbb{Z}\right\} \\
    &= \left\{ 60\sum_{i = 1}^k x_iy_i,  x_i, y_i \in \mathbb{Z} \right\} \\
    &= 60\mathbb{Z}
  \end{align*}
\end{itemize}

From which we can conclude!

\ 

\begin{theorem}\label{idealops}
  Let $I = n\mathbb{Z}, J = m\mathbb{Z}$ two ideals of $\mathbb{Z}$. Then: 
  \begin{gather*}
    I \cap J = \lcm(n, m)\mathbb{Z} \\
    I + J = \gcd(n, m)\mathbb{Z} \\
    I \cdot J = (n \cdot m)\mathbb{Z}
  \end{gather*}
\end{theorem}

\aparte{Example}{
  Consider $A = \mathbb{R}[x]$ all polynomials on one variable with real coefficients\footnotemark. This forms a ring as is trivial to verify. Then, we consider the following: 
  \begin{gather*}
    I = \{(x + 5)f(x), f(x) \in \mathbb{R}[x]\} \\
    J = \{(x^2 + 2)f(x), f(x) \in \mathbb{R}[x]\}
  \end{gather*}
  which are comprised of all polynomials divisible by $(x + 5)$ and $(x^2 + 2)$, respectively. Then, we have:
  \begin{gather*}
    I \cap J = \{(x + 5)(x^2 + 2)f(x), f(x) \in \mathbb{R}[x]\} \\
    I \cdot J = \left\{\sum_{i = 0}^k (x + 5)f_i(x) \cdot (x^2 + 2)g_i(x)\right\} = \{(x + 5)(x^2 + 2)f(x)\} \\
    I + J = \{(x + 5) f(x) + (x^2 + 2) g(x)\}
  \end{gather*}
  We can find $f(x), g(x)$ such that $(x + 5) f(x) + (x^2 + 2) g(x) = 1 \in \mathbb{R}[x]$ (constant polynomial of value 1). For example, take 
  \[
    (x + 5)(x - 5)\left(\frac{-1}{27}\right) - (x^2 + 2)\left(\frac{-1}{27}\right) = (x^2 - 25 - x^2 - 2)\left(\frac{-1}{27}\right) = 1
  \]

  Can we do that for any pair of polynomials in $\mathbb{R}[x]$?
}
\footnotetext{If you want to see me get pedantic about notation for life half a page, go look at appendix C.}

\marginpar{Week 9}

\begin{definition}\label{princid}
  Let $S \subset A$. Let $I$ be the minimal ideal containing $S$. Then, we denote $I = (S)$ the \emph{ideal generated by the set} $S$. It means: 
  \[
    (S) = \left\{\sum_i s_i a\right\}_{s_i \in S, a \in A}
  \] 
  $I$ is called \emph{principal} if $I = (x) = \{xa, x \in I\}_{a \in A}$ is generated by a single element. 
\end{definition}
\aparte{Examples}{
  $A$ and $\{0\}$ are principal, being generated by $1$ and $0$ respectively. Additionally, $n\mathbb{Z} = (n)$ is principal. 
}

\begin{theorem*}
  $A$ is a field $\Leftrightarrow$ $A, \{0\}$ are the only ideals in $A$
\end{theorem*}
\begin{proof}
  We prove both directions separately: 
  \begin{itemize}
    \item[$\Rightarrow$] $A$ is a field, consider an ideal $I$ that isn't $\{0\}$ and an element $a \in I$, which is not 0. Since we're in a field, and it is non-zero, there exists $a^{-1} \in A$. By definition of an ideal, we have that $a a^{-1} \in I \Rightarrow 1 \in I \Rightarrow I = A$. 
    \item[$\Leftarrow$] Let $A$ be a ring such that $A$, $\{0\}$ are its only ideals. Therefore, we consider an $0 \neq a \in A$, and the ideal it generates. Since $a \neq 0$,we know that it must generate $A$, and that there must exist a $y \in A$ such that $ya = 1$, meaning that $y = a^{-1}$ by definition, and $A$ is a field as a consequence of its existence.  
  \end{itemize} 
\end{proof}

\section{Quotient rings}

\begin{definition}
  An \emph{equivalence relation} $\sim$ on a set $E$ is a relation such that for any $a, b, c \in E$, we have: 
  \begin{itemize}
    \item $a \sim a$, meaning it is \emph{reflexive}
    \item $a \sim b \Leftrightarrow b \sim a$, meaning it is \emph{symmetric}
    \item $a \sim b, b \sim c \Rightarrow a \sim c$, meaning it is \emph{transitive}
  \end{itemize}

  A \emph{congruence relation} $\sim$ on a commutative ring $A$ is an equivalence relation such that for any $a, b, c, d \in A$
  \[
    \begin{cases}
      a \sim b \\
      c \sim d
    \end{cases} \Rightarrow 
    \begin{cases}
      a + c \sim b + d \\
      ac \sim bd
    \end{cases}
  \]
\end{definition}

\begin{theorem*}
  If $I \subset A$ is an ideal, then the relation : 
  \[
    a \sim b \Leftrightarrow (b - a) \in I
  \]
  is an equivalence relation, and if it is a congruence relation, then the set $I = \{a \in A: a \sim 0\}$ is an ideal in $A$. 
\end{theorem*}
\begin{proof}
  We first check all of the properties of an equivalence relation. We have: 
  \begin{itemize}
    \item Any ideal contains the 0 element, meaning that $(a - a) \in I \Rightarrow a \sim a$. This makes $\sim$ reflexive. 
    \item $I$ must be an additive subgroup of $A$. Therefore, it must contain $b - a$ and $-(b - a) = a - b$, meaning that if $a \sim b$, then $b \sim a$. $\sim$ is therefore symmetric. 
    \item Consider $a, b, c \in A$ such that $a \sim b, b \sim c$. Therefore, this means that $c - b \in I, b - a \in I$. Now, consider that $c - a = (c - b) + (b - a)$ is the sum of two elements of $I$: since $I$ is an additive subgroup, that must mean that $c - a \in I$, meaning $a \sim c$. Therefore $\sim$ is transitive. 
  \end{itemize}
  Now that we have checked the properties of an equivalence relation, we must check those for a congruence relationship: consider $a \sim b, c \sim d$ in $A$. Then: 
  \[
    \begin{cases}
      (b + d) - (a + c) = (b - a) + (d - c) \in I \\
      bd - ac = (b - a)(d - c) = e(b - a) \in I
    \end{cases}
  \]
  Where the last step is motivated by the fact that $e = d - c$ is an element of $A$, and by the definition of an ideal. This concludes the proof of the first part of the theorem. 
  
  Then, consider $a \sim 0, b \sim 0$. We have: $a + b \sim 0, 0 \sim 0, -a \sim 0$, which completes the subgroup requirement, as well as $x \sim x \Rightarrow a \cdot x \sim 0 \cdot x \Rightarrow a \cdot x \sim 0 \Rightarrow \{a \in A: a \sim 0\}$ is an ideal! 
\end{proof}

\begin{theorem*}
  Let $A$ be a commutative ring, $\sim$ a congruence relation over $A$ such that $1 \not\sim 0$. Then, the set of congruence classes $A/\{x \in A : x \sim 0\} := A/{\sim}$ is a commutative ring. 
\end{theorem*}
\begin{proof}
  Notate $\bar{a} = \{x \in A: x \sim a\}$. Define $\bar{a} + \bar{b} = \bar{a + b}$, $\bar{a} \cdot \bar{b} = \bar{ab}$. These are well-defined thanks to the properties on $\sim$. Most importantly, $\bar{1} \in A/{\sim}$. 
\end{proof}

\aparte{Example}{
  Consider the ring of polynomials with real coefficients $\mathbb{R}[x]$. Let $I = \langle (x^2 - 4) \rangle$, and consider the commutative ring $B = \mathbb{R}[x]/I$. Within it, we have: 
  \[
    \bar{(x + 2)} \cdot \bar{(x + 1)} = \bar{x^2 + 3x + 2} = {\color{redish} \bar{x^2 + 3x + 2} - \bar{x^2 - 4}} = \bar{3x + 6}
  \]
  where the step in red is justified as a way to find the remainder of the function by the defined congruence relation. Another example: 
  \[
    \bar{x} \cdot \bar{x} = \bar{x^2} \mathbin{\color{redish}=} \bar{4}
  \]
  through a similar process as earlier. One can also look for the zero divisors (recall definition \ref{zerodiv-def}) within this ring. Consider: 
  \[
    \bar{(x + 2)}\bar{(x - 2)} = \bar{(x^2 - 4)} \mathbin{\color{redish}=} \bar{0}
  \]
  since $(x + 2), (x - 2)$ are non-zero, but their product is, this means that they are zero divisors, and that $B$ is not an integral domain. 
  
  As an exercice, one can show that any element in $B$ can be written under the form $\bar{ax + b}, a, b \in \mathbb{R}$. 
}

\begin{definition}
  Recall the definition of a principal ideal (Definition \ref{princid}). A commutative ring where every ideal is principal is called a \emph{principal ring}. An integral domain where every ideal is principal is called a \emph{principal integral domain} (PID). 
\end{definition}

This means that any field is a PID, since it only has two ideals, and they are both principal ($A$ is generated by 1, ${0}$ is generated by 0).

\begin{theorem*}
  $\mathbb{Z}$ is a PID. 
\end{theorem*}
\begin{proof}
  If $I = \{0\}$, then $I = (0)$. Suppose then that $I \neq \{0\}$. Therefore, there exists an $0 \neq a \in I$, such that $a \in I, -a \in I \Rightarrow |a| \in I$. Consider $d$ the smallest positive element in $I$. Then, for any $n \in I$, by euclidean division, $n = kd + r, 0 \leqslant r \leqslant d-1\Rightarrow r \in I$. Since $d$ is the smallest positive integer in $I$, then it must be the case that $r = 0$, by definition of the ideal. Therefore, $I = (d)$.  
\end{proof}

\section{Ring homomorphisms}

\begin{definition}
  Let $A, B$ two commutative rings. Then, $f: A \to B$ is a \emph{ring homomorphism} if, for $a, b \in A$ and well-defined operations
  \begin{gather*}
    f(a + b) = f(a) + f(b) \\
    f(ab) = f(a)f(b) \\
    f(1_A) = 1_B \\
  \end{gather*}
\end{definition}
\begin{theorem*}
  Let $f: A \to B$ be a ring homomorphism. Then, $\ker f$ is an ideal, and $\operatorname{im} f$ is a subring.
\end{theorem*}

\begin{definition}
  A \emph{subring} is a subset of a ring that is a ring with respect to the same operations and constants as the superset. 
\end{definition}

\aparte{Examples}{
  Consider $C$ an arbitrary subring of $\mathbb{Z}$. Then, it must contain $0, 1$, and be defined over the same $+, \cdot$. Therefore, since it must be closed under addition, it must contain $-1$, as well as
  \[
    \underbrace{1 + 1 + ... + 1}_{n}
  \]
  for any $n \in \mathbb{Z}$. This means that $C = \mathbb{Z}$.

  For a more interesting example, take a ring homomorphism $f: \mathbb{Z}/n\mathbb{Z} \to \mathbb{Z}/m\mathbb{Z}$, with $n, m, \in \mathbb{N}$. We can make a few observations about it.
  \begin{itemize}
    \item $f$ cannot map to a proper subring of $\mathbb{Z}/m\mathbb{Z}$. We know that $[1]_m \in \operatorname{im} f$, meaning that 
    \[
      \underbrace{[1]_m + ... + [1]_m}_{k \text{ times}} = [k]_m \in \operatorname{im} f \forall k < m
    \]
    Therefore, $\operatorname{im} f = \mathbb{Z}/m\mathbb{Z}$. 
    \item $f([n]_n) = f([0]_n) = [0]_m$, but also, $f([n]_n) = f([1]_n \cdot n) = [1]_m \cdot n = [n]_m$, meaning that $[n]_m = 0 \Rightarrow n \equiv 0 (\mod m)$, which implies $m|n$. 
    \item Additionally, $f$ is such that $[1]_n \stackrel{f}{\mapsto} [1]_m$, meaning that $[k]_n \stackrel{f}{\mapsto} [k]_m$ for any $k$. This implies that $f$ is unique. 
  \end{itemize}
  
  In conclusion: 
  \begin{theorem*}
    There exists a ring homomorphism $f: \mathbb{Z}/n\mathbb{Z} \to \mathbf{Z}/m\mathbb{Z}$ if and only if $m|n$. In that case, then $f$ is unique, and its image is equal to $\mathbb{Z}/m\mathbb{Z}$. 
  \end{theorem*}
}

Now for A Quick Tour of This Land's Characteristic Rings. 

Let $A$ a ring. There exists only a single ring homomorphism $\tau: \mathbb{Z} \to A$. This is due to the fact that $\tau(0) = 0, \tau(1) = 1_A \Rightarrow \tau(k) = \tau(1 + 1 + ... + 1) = 1_A + ... + 1_A = k \cdot 1_A \in A$. Therefore, the mapping is uniquely determined, and $\tau(n \cdot k) = \tau(n) \cdot \tau(k)$. 

There are two possibilities to characterize the kernel of this transformation, either $\ker \tau = (0)$, or $\ker \tau = (d)$ with $d \geqslant 2$: in short, it cannot be 1.\footnote{This makes sense in accordance to the definition of a ring homomorphism: $\tau(1) \neq 0$ for any $\tau$}. Let us formalize this: 

\begin{definition}
  Let $A$ be a ring, $\tau$ the unique homomorphism from the integers to it. Then, the \emph{characteristic} of $A$ is 
  \[
    c_A = \begin{cases}
      0 &, \ker \tau = 0 \\
      d &, \ker \tau = d \geqslant 2
    \end{cases}
  \]
\end{definition}
\aparte{Examples}{
  The characteristic of the real numbers is 0, since the field homomorphism: 
  \begin{align*}
    \tau : \mathbb{Z} &\to \mathbb{R} \\
                n     &\mapsto n
  \end{align*}
  maps 0 (and only 0) to 0. Therefore, its kernel is $\{0\}$, and $C_\mathbb{R} = 0$. A similar argument gives us that $C_\mathbb{Z} = 0$, and we can consider
  \begin{align*}
    \tau : \mathbb{Z} &\to \mathbb{Z}/n\mathbb{Z} \\
              k       &\mapsto [k]_n
  \end{align*}
  Which maps every multiple of $n$ to 0. Therefore, $\ker \tau = (n)$, and $C_{\mathbb{Z}/n\mathbb{Z}} = 0$. 
}

\begin{theorem*}
  $A$ is an integral domain $\Rightarrow c_A = 0$ or $c_A  = p$ a prime.  
\end{theorem*}
\begin{proof}
  Suppose $c_A = m \cdot k$ for $m, k > 1$. Then, $\tau(m) \cdot \tau(k) = \tau(m \cdot k) = 0 \in A$, meaning that there are two nontrivial zero divisors in $A$. 
\end{proof}
This holds for fields as well, since they are integral domains necessarily. 

\begin{definition}
  Let $A, B$ be two rings. Then, the \emph{direct product} is given by $A \times B = \{(a, b), a \in A, b \in B\}$. It has ring structure, with neutral elements $(0_A, 0_B), (1_A, 1_B)$, and component wise operations. 
\end{definition}

\aparte{Examples}{
  Consider the ring $A = \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}$, and let us compute its characteristic. We first describe the homomorphism: 
  \begin{align*}
    \tau : \mathbb{Z} &\to \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}
  \end{align*}
  such that $\tau(1) = ([1]_n, [1]_m)$. Therefore, we know that
  \[
    \tau(k) = ([k]_n, [k]_m) = ([0]_n, [0]_m) \Leftrightarrow k \equiv 0\ (\mod n) \land k \equiv 0\ (\mod m)
  \]
  The characteristic is the smallest element of such form: $c_A = \lcm(n, m)$. 

  This can be generalized to the characteristic of any product of two rings $A, B$: $c_{A \times B} = \lcm(c_A, c_B)$. This lets us construct fields of prime characteristics, but that aren't fields: 
  \[
    A = \mathbb{Z}/p\mathbb{Z} \times \mathbb{Z}/p\mathbb{Z}
  \]
  has prime characteristic $c_A = \lcm(p, p) = p$, but has non-trivial zero divisors as well: 
  \[
    (0, 1) \cdot (0, 1) = (0, 0)
  \]
  Which means it is not an integral domain. 
}

\aparte{Method}{
  Let's compute more characteristics! 
  
  Let $B = \mathbb{Z} \times \mathbb{Z}/n\mathbb{Z}$. Then, using $\tau(k) = (k, [k]_n)$, we can see that the kernel of $\tau$ must be equal to $\{0\}$, since no other term will leave a 0 in the first spot. Since $\ker \tau = (0)$, then $c_B = 0$. 

  Let $D = \mathbb{Z}/n\mathbb{Z}[x]$ be the ring of polynomials over $x$ with coefficients in $\mathbb{Z}/n\mathbb{Z}$. The homomorphism must be such that $\tau(1) = [1]_n$, meaning that $\tau(k) = [k]_n = 0 \Leftrightarrow n|k$. This means that $\ker \tau = (n)$, meaning that $c_D = n$. 
}

\section{The Chinese Remainder Theorem}
\marginpar{Week 10}

\begin{theorem}[Chinese Remainder Theorem]
  Let $A$ be a commutative ring, $I, J \subset A$ two ideals such that $I + J = A$. Then, there exists a ring isomorphism\footnotemark 
  \begin{align*}
    f: A/(I \cap J)      &\stackrel{\sim}{\to} A/I \times A/J \\
       f([x]_{I \cap J}) &\mapsto ([x]_I, [x]_J)
  \end{align*}
\end{theorem}
\footnotetext{A ring isomorphism is a ring homomorphism that is bijective (inversible).}
\begin{proof}
  We will first prove that $f$ is a homomorphism, before proving its bijectivity. 
  \begin{enumerate}
    \item[\small(1)] $f$ is a ring homomorphism. This can be shown by checking ring operations on it, which is easy and tedious after pointing out that we map $1$ to $([1]_I, [1]_J)$. 
    \item[\small(2)] We want to show that $f$ is surjective by showing that for any $a_1, a_2 \in A$, there exists an $a \in A$ such that $a \equiv a_1 (\mod I)$ and $a \equiv a_2 (\mod J)$. Since $I + J = A$, then we can write, for $i \in I, j \in J$: 
    \[
      a_1 - a_2 = -i + j \Leftrightarrow a_1 + i = a_2 + j := a \in A
    \]
    which by construction gives us an $a \in A$ with the properties we want. This implies that for any $x \in A$, we can define $f(x) = ([x]_I, [x]_J)$, which is surjective. 
    \item[\small(3)] To prove that $f$ is injective, We consider another $b$ such that $b \equiv a_1 (\mod I) \equiv a_2 (\mod J)$. Then, there exist $i', j'$ such that $b = a_1 + i' = a_2 + j'$, meaning $b - a = i - i' = j - j' \in I \cap J$. This is means that it has reminder 0 in $A$\footnote{This is handwavy, but I mean. It's not any less clear than the proof in the course, and it's the best explanation I've found. I'll update the document once I find better.}, meaning that our map is injective. 
  \end{enumerate}
  Therefore, $f$ is surjective and injective: therefore, is a bijective ring homomorphism, and by definition is a ring isomorphism.
\end{proof}

Over $\mathbb{Z}$, this motivates a new corollary. 

\begin{corollary}
  Let $n, m \in \mathbb{Z}$ coprime. Then, for any $a_1, a_2 \in \mathbb{Z}$, there exists an $a$ such that it is equivalent to $a_1$ mod $n$, and $a_2$ mod $m$. The set of solutions is given by $\{a + nm\mathbb{Z}\}$. 
\end{corollary}
\begin{proof}
  By Bezout's theorem, there exist $x, y \in \mathbb{Z}$ such that 
  \[
    xm + yn = 1 \Rightarrow (m) + (n) = \mathbb{Z}
  \]
  This allows us to apply the CRT directly, showing that the $a$ we are looking for exists. The set of solutions is therefore equal to $\{a + nm\mathbb{Z}\}$, applying Theorem \ref{idealops} to $I \cap J$ after recognizing that $\gcd(n, m) = 1 \Rightarrow \lcm(n, m) = nm$. 
\end{proof}

\aparte{Some more}{
  We can also generalize this result over more than two congruences! For $d_1, ..., d_r \in \mathbb{Z}$ that are pairwise coprime. Then, for any set of congruences $a_1, ..., a_r \in \mathbb{Z}$, there exists an $a \in \mathbb{Z}$ such that 
  \[
    \begin{cases}
      a \equiv a_1\  (\mod d_1) \\
      a \equiv a_2\  (\mod d_2) \\
      ... \\
      a \equiv a_r\  (\mod d_r) \\
    \end{cases}
  \]
  This choice of $a$ is unique up to the ideal $(d_1...d_r)$, meaning that the set of solutions is given by $\{a + (d_1...d_r)\mathbb{Z}\}$. 
  
  Proof of this can be done by induction over $r$. 
}

\begin{theorem*}
  If $A \simeq B$ are isomorphic, then their groups of units are isomorphic, as well. The units of a ring are its invertible elements with respect to multiplication. We notate this $A^* \simeq B^*$. 
\end{theorem*}

As a corollary to this, one can verify the formula that $\tot(nm) = \tot(n) \tot(m)$ when $n$ and $m$ are equal!. In fact, by CRT, we can write
\[
  \mathbb{Z}/nm\mathbb{Z} \simeq \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}
\]
which means that their groups of units are isomorphic as well. Additionally, we have that 
\[
  \left(\mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}\right)^* \simeq \left(\mathbb{Z}/n\mathbb{Z}\right)^* \times \left(\mathbb{Z}/m\mathbb{Z}\right)^*
\]

Therefore, we get : 
\[
  \tot(nm) = |\left(\mathbb{Z}/nm\mathbb{Z}\right)^*| = |\left(\mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}\right)^*| = |\left(\mathbb{Z}/n\mathbb{Z}\right)^*| |\left(\mathbb{Z}/m\mathbb{Z}\right)^*| = \tot(n)\tot(m)
\]

\section{Polynomial Rings}

\begin{definition}
  Let $A$ be a commutative ring. Then, we define the \emph{ring of polynomials on $A$} as 
  \[
    A[x] = \{a_0 + a_1x + ... + a_nx^n\}_{n \in \mathbb{N}}
  \]
  with the usual polynomial addition and multiplication. Since it contains $0$ and $1$, it is a well defined ring, and it is commutative by definition of addition and multiplication. 
\end{definition}
\begin{definition}
  If $f \in A[x]$ is nonzero, then we define the \emph{degree} of $f(x) = a_0 + ... + a_nx^n$ as the largest $n$ such that $a_n \neq 0$. We then write $\deg(f) = n$. If $f = 0$, then $\deg(f) = -\infty$ by convention\footnotemark.
\end{definition}
\footnotetext{To convince yourself of why, consider the (intuitive) property of two polynomials $P, Q$: $\deg(P \cdot Q) = \deg P + \deg Q$. In this case, since $0 \cdot P = 0$, we want $\deg(P \cdot 0) = \deg P + \deg 0 = \deg 0$, which is only matched if $\deg 0 = -\infty$.}

\begin{theorem*}
  Let $f, g$ be two polynomials. Then, 
  \begin{gather*}
    \deg (f + g) \leqslant \max\{\deg f, \deg g\} \\
    \deg (f \cdot g) = \deg(f) + \deg(g)
  \end{gather*}
\end{theorem*}
\begin{proof}
  Direct computation. 
\end{proof}

\begin{theorem*}
  Let $A$ be an integral domain. Then $A[x]$ is an integral domain, and its units are the units of $A$. 
\end{theorem*}
\begin{proof}
  We can first check to see whether or not it is an integral domain. To do this, consider two polynomials such that their product is 0: 
  \begin{gather*}
    f \cdot g = 0 \Leftrightarrow \deg f + \deg g = -\infty \\
    \Rightarrow \deg f = -\infty \text{ or } \deg g = -\infty \\
    \Rightarrow f = 0 \text{ or } g = 0
  \end{gather*}
  
  Then, we consider the units: 
  \begin{gather*}
    f \cdot g = 1 \Leftrightarrow \deg f + \deg g = 0 \\
    \Rightarrow f = a_0, g = b_0 \in A : a_0 \cdot b_0 = 1
  \end{gather*}
\end{proof}


\begin{theorem}[Euclidean division in a polynomial ring]
  Let $F$ a field, $f, d \in F[x]$ of degree $\geqslant 1$. Then, there exist $q, r \in F[x]$ such that 
  \[
    f(x) = d(x)q(x) + r(x)
  \]
  and either $r = 0$ or $\deg r < \deg d$. 
\end{theorem}
\begin{proof}
  There are multiple cases: 
  \begin{itemize}
    \item If $\deg f < \deg q$, then $f(x) = 0 \cdot d(x) + f(x)$, meaning $f = r$. 
    \item If $\deg f >= \deg q$, then we have: 
    \begin{gather*}
      f(x) = a_0 + ... + a_mx^m \\
      d(x) = b_0 + ... + b_nx^n, n \leqslant m
    \end{gather*}
    meaning that we can rewrite
    \[
      f(x) - d(x) \cdot \frac{a_m}{b_n}x^{m-n} = p_1(x)
    \]
    such that $p_1$ is of smaller degree than $f$. If $\deg p_1 \geqslant \deg d$, repeat: 
    \[
      f(x) - d(x) \cdot \frac{a_m}{b_n}x^{m-n} \cdot \frac{a_{m - 1}}{b_n}x^{m-n-1} \cdot ...
    \]
    Until you end up at a form such that $\deg (f - dq) < \deg d$. Since the degree is strictly decreasing at every step, this is guaranteed to happen at some point, and therefore, the process terminates.
  \end{itemize}
\end{proof}

\aparte{Method}{
  This is much easier to do as a polynomial long division! I'll put resources here on how to do it and how to do it fast, since there is literally no cool way to typeset them\footnotemark[0]. 
}
\footnotetext{Read: I lack the time to typeset this properly}

\begin{definition}
  A commutative ring $A$ is called an \emph{Euclidean domain} if it is an integral domain and there exists a function $\nu: A \smallsetminus \{0\} \to \mathbb{N}$ such that $\forall a, b \in A, b \neq 0 \ \exists q, r \in A: a = qb + r$ and either $r = 0$ or $\nu(r) < \nu(b)$.
\end{definition}
\aparte{Examples}{
  Let us consider some examples: 
  \begin{enumerate}
    \item[(1)] $\mathbb{Z}$ with $\nu(n) = |n|$. 
    \item[(2)] Any field: $a = bq + 0$. 
    \item[(3)] $\mathbb{F}[x]$ over a field $\mathbb{F}[x]$, with $\nu(f) = \deg(f)$. 
  \end{enumerate}
}

\begin{theorem*}
  A Euclidean domain is a PID. 
\end{theorem*}
\begin{proof}
  Let $E$ a Euclidean domain, $I \subset E$ an ideal within $E$. If $I = \{0\}$, then $I = (0)$. If it isn't, then consider an element $d$ within it, non-zero, such that $\nu(d)$ is minimal over $I$. Suppose $a \in I$. Therefore, there exists $q, r$ such that $a = qd + r$. Since $r$ is $I$, then either $\nu(r) < \nu(d)$, which is impossible, since it contradicts our definition of $d$, or $r = 0$. Therefore, $r = 0$, meaning $a = qd$, meaning $I = (d)$ which makes $E$ a PID. 
\end{proof}

\begin{theorem}[Unproven] 
  If $F$ is a field, then $F[x]$ is a Euclidean domain. 
\end{theorem}

\marginpar{Week 11}
\begin{definition}
Let $A$ be a commutative ring. We say that $a$ \emph{divides} $b$ for $a, b \in A$ if there exists $c \in A: b = ac$. Over an integral domain, we also define: 
\begin{itemize}
  \item The \emph{$\gcd$} of $a, b$, is $d$ such that it divides $a$ and $b$, and $(c|a \land c|b) \Rightarrow c|d \ \forall c$
  \item The \emph{$\lcm$} of $a, b$, is $l$ such that $a$ and $b$ divide it, and $(a|m \land b|m) \Rightarrow l|m \ \forall m$
\end{itemize} 
In general, these two are not unique. 
\end{definition}

\begin{theorem*}
  Let $A$ be an integral domain. If $d_1, d_2$ are two $\gcd$s of $a, b$, then $d_1 = xd_2$, with $x \in A^*$ a unit, and if $l_1, l_2$ are two $\lcm$s of $a, b$, then $l_1 = yl_2$, with $y \in A^*$ a unit. 
\end{theorem*}
\begin{proof}
  We only prove the case for the gcd: the argument is similar for the lcms. 
  Since we are in an integral domain, we know that there exist $x, z$ such that $d_1 = xd_2, d_2 = zd_1$. This means that 
  \[
    d_1 = xd_2 = xzd_1 \Rightarrow d_1(1 - xz) = 0 \stackrel{d_1 \neq 0}{\Rightarrow} xz = 1
  \]
  meaning that $x$ and $z$ are two units. 
\end{proof}

\begin{definition}
  Let $A$ be an integral domain. Then, we say that $a, b \in A$ are associates if there exists a unit $u \in A^*$ such that $a = bu$. 
\end{definition}

\aparte{Remark and examples}{
  Associates generate the same ideals in a PID!

  If $g = uf$, then $g \in (f)$, meaning $(g) \subset (f)$. Similarly and symmetrically, we have that $f = gv \Rightarrow f \in (g) \Rightarrow (f) \subset (g)$. Since we have mutual inclusion, we get $(f) = (g)$. 

  In $\mathbb{Z}$, the units are $\pm 1$, meaning that two integers $n, m$ are associates only if they are equal or relative opposites ($n = -m$). This implies $(m) = (-m)$. 

  In $F[x]$, with $F$ a field, the units are $F \smallsetminus \{0\}$. Therefore, two polynomials $f, g$ are associates if they are a non zero constant apart, $f = \alpha g, \alpha \in F^*$. 
}

\aparte{Properties}{
  Let $a, b \in A$, $A$ a Euclidean domain. Then, we have: 
  \begin{enumerate}
    \item[1.] $\gcd(a, b)$ can be found by successive euclidean division: 
    \[
      \begin{cases}
        a = q_1b + r_1 \\
        b = q_2r_1 + r_2 \\
        ...
      \end{cases}
    \]
    \item[2.] $(a) + (b) = (\gcd(a, b))$ 
    \item[3.] $(a) \cap (b) = (\lcm(a, b))$
    \item[4.] $\gcd(a, b) = 1 = \gcd(a, c) \Rightarrow \gcd(a, bc) = 1$
    \item[4.] $\gcd(a, b) = 1 \Rightarrow \lcm(a, b) = ab$
  \end{enumerate}
}

\section{CRT but again}

\begin{theorem}[CRT over Euclidean domains]
  Let $E$ be a Euclidean domain, and consider  $m_1, ..., m_r \in E: \gcd(m_i, m_j) = 1, i \neq j$. Then, the function: 
  \begin{align*}
    f : E/(m_1...m_r) &\to E/m_1 \times ... \times E/m_r \\
          [x]_{(m_1...m_r)} &\mapsto ([x]_{(m_1)}, ..., [x]_{(m_r)})
  \end{align*}
  is a ring homomorphism
\end{theorem}
\aparte{Sketch of proof}{
  The proof follows a few basic steps. 
  \begin{enumerate}
    \item[1)] It is a ring isomorphism by construction
    \item[2)] We verify surjectivity by induction over the factors: first, we construct $a_{12}$ such that it is equivalent to $a_1$ mod $m_1$ and $a_2$ mod $m_2$. To do this, we had to use the fact that $\gcd(m_1, m_2) = 1 \Rightarrow (m_1) + (m_2) = E$. Therefore, we can construct $a_{123}$ such that it is equivalent to $a_{12} \mod m_1m_2$ and $a_3 \mod m_3$, using the fact that $\gcd(m_3, m_1m_2) = 1$. Continue doing this until every congruence is met! Then, we get an $a_{12...r}$ which maps to our original $(a_1, ..., a_r)$, meaning our function is surjective. 
    \item[3)] We verify injectivity by considering an $a, b: a \equiv a_i (\mod m_i), b \equiv a_i (\mod m_i) \ \forall i$. Therefore, we have 
    \[
      a - b \in \bigcap_{r} (m_i) = (\lcm(m_1...m_r)) = (m_1...m_r)
    \]
  \end{enumerate}
}
\begin{corollary}
  Let $F$ be a field, $\{f_1, ..., f_r\}$ a family of polynomials of $F[x]$ such that their pairwise $\gcd$ is 1. Then,
  \[
    F[x]/(f_1...f_r) \simeq F[x]/f_1 \times F[x]/f_2 \times ... \times F[x]/f_r
  \]
\end{corollary}
\begin{definition}
  A polynomial is said to be \emph{monic} if its leading coefficient (the coefficient of the highest power of $x$) is equal to 1. 
\end{definition}
\aparte{Remark}{
  The $\gcd$ of two polynomials is defined up to a nonzero constant factor. There exists a \textit{unique} $\gcd$ that is monic, but an infinite number of $\gcd$s that are multiples of the original. 
}

\section*{Application: Systems of polynomial congruences}
\addcontentsline{toc}{subsection}{Application: Systems of polynomial congruences}

\aparte{Exercice}{
  Let $\mathbb{F}_3$ a field, and consider $\mathbb{F}_3[x]$. Find all the solution of the following system of congruences: 
  \[
    \begin{cases}
      f(x) \equiv x + 1 \ (\mod (x^2 + 1) = g_1) \\
      f(x) \equiv 1 \ (\mod (x) = g_2) \\
      f(x) \equiv -x \ (\mod (x^2 - 1) = g_3) \\
    \end{cases}
  \]
}
The three functions can be verified to have pairwise $\gcd$ equal to 1, more often than not by finding $a, b \in \mathbb{F}_3: ag_i + bg_j = 1, i \neq j$.
\[
  \begin{cases}
    x^2 + 1 + x{\color{redish}(2x)} = 1 \\
    (x^2 - 1)\cdot{\color{redish}2} + x{\color{redish}(x)} = 1 \\
    (x^2 + 1)\cdot{\color{redish}2} + (x^2 - 1) = 1
  \end{cases}
\] 
Therefore, by the Chinese Remainder Theorem, there exist solutions to the system, and they are of the form $a + (g_1g_2g_3)$. 

How do we find the $a \in \mathbb{F}_3[x]$ to solve this? First, take any two congruences: 
\[
  \begin{cases}
    f \equiv x + 1 \ (\mod (x^2 + 1)) \\
    f \equiv 1 (\mod (x))
  \end{cases}
\]
We need to find $h, g$ such that 
\[
  (x^2 + 1)h(x) + x + 1 = x g(x) + 1 \Rightarrow (x^2 + 1)h(x) - xg(x) = -x
\]
We can verify that $h = 1, g = 2x$ gives us $(x^2 + 1) \cdot {\color{redish}1} + x \cdot {\color{redish}(2x)} = 1$, meaning that we have 
\[
  f(x) = (x^2 + 1)(-x) + x + 1 = -x^3 + 1 \equiv x + 1 \ (\mod (x^3 + x))
\]
Since $\gcd(x^3 + x, x^2 - 1)$, this can be used as a new congruence!
\[
  \begin{cases}
    f(x) \equiv x + 1 \ (\mod x^3 + x) \\
    f(x) \equiv -x \ (\mod x^2 - 1)
  \end{cases}
\]

We finish in the same way: 
\begin{gather*}
  h(x)(x^3 + x) + x + 1 = g(x)(x^2 - 1) - x \\
  h(x)(x^3 + x) - g(x)(x^2 - 1) = x - 1 \\
  x(x^3 + x) + (-x^2 + 1)(x^2 - 1) = -1 \\
  \Rightarrow \underbrace{x(-x + 1)}_{h(x)}(x^3 + x) + \underbrace{(-x^2 + 1)(-x + 1)}_{-g(x)}(x^2 - 1) = x - 1
\end{gather*}
We replace all of this in our definition, as we did earlier: 
\begin{align*}
  f(x) 
  &= x(-x + 1)(x^3 + x) + x + 1 \\
  &= x(-x^4 - x^2 + x^3 + x) + x + 1 \\
  &= -x^5 - x^3 + x^4 + x^2 + x + 1 \\
  &\equiv x^4 - x^3 + x^2 + 1 \ (\mod x^5 - x) \\
  &\equiv x^4 + 2x^3 + x^2 + 1 \ (\mod x^5 - x)
\end{align*}
giving us our solution!

\aparte{Method}{
  How do you solve a system of congruences?

  Consider the system 
  \[
    f \equiv h_1 \ (\mod g_1) \\
    f \equiv h_2 \ (\mod g_2)
  \]
  Since $\gcd(g_1, g_2) = 1$ There exist $t_1, t_2$ such that 
  \[
    t_1g_1 + t_2g_2 = 1
  \]
  Meaning that $f = h_1t_2g_2 + h_2t_1g_1$ is a solution\footnotemark! This can be generalized to $r$ equiations: let $G = g_1...g_r, G_i = G/g_i$. Therefore, $\gcd(G_i, g_i) = 1$, meaning that for any $i$; we can find $t_i, s_i: t_iG_i + s_ig_i = 1$. Therefore, our $f$ is a linear combination: 
  \[
    f = \sum_{i = 1}^r h_iG_it_i
  \]
  which satisfies the right congruences.
}
\footnotetext{You can verify the congruences easily.}

\begin{definition}
  An element $c$ of a ring $A$ is \emph{irreducible} if it is non-zero, not a unit, and $c = ab$ with either $a \in A^*$ or $b \in A^*$. 
\end{definition}

\begin{definition}
  $I \subset A$ is \emph{maximal} if there is no ideal $J \subset A$ such that $I \subsetneq J \subsetneq A$
\end{definition}

\begin{theorem}
  Let $A$ a principal ideal domain. Then, $p \in A$ is irreducible if and only if $p \neq 0$ and $(p) \subset A$ is maximal.
\end{theorem}
\begin{proof}
  We will prove both directions separately. 
  \begin{itemize}
    \item[($\Rightarrow$)] $p$ is irreducible. Suppose that there exists a proper subset $J \subsetneq A$ such that $(p) \subsetneq J$. Since $A$ is a PID, then $J = (d)$, meaning that we can write $p = dt$. Since $p$ is irreducible
    \begin{itemize}
      \item either $d$ is a unit, but that would mean that $(d) = (1) = A$, which contradicts the fact that $J$ is a proper subset of $A$; 
      \item or $t$ is a unit, in which case $p$ and $d$ are associates, and $(d) = (p)$, which contradicts the condition $I \subsetneq J$.
    \end{itemize}
    This means that $(p)$ must be maximal. 
    \item[($\Leftarrow$)] $(p) \subset A$ is maximal. Suppose that $p$ is not irreducible, meaning that there exist $y, z$ that aren't units and that are such that $p = yz$. This means $(p) \subset (y) \subsetneq A$. Let's assume towards contradiction that $(p) = (y)$. Then, $y = pt \Rightarrow p = yz = ptz \Rightarrow p(1 - tz) = 0$. This implies either that $p = 0$ (which is impossible as we assume it isn't) or that $tz = 1$ which is only possible if $z$ is a unit, which we said was not the case. 

    Therefore, if there exist $y, z \notin A^*: p = yz$, then $(p) \subsetneq (y) \subsetneq A$, which contradicts our assumption that $(p)$ was maximal. Therefore, $p$ is irreducible.
  \end{itemize}
\end{proof}

\begin{theorem}
  Let $A$ be a Euclidean domain. Then, $I \subset A$ is maximal $\Leftrightarrow A/I$ is a field $\Leftrightarrow I = (d): d$ is irreducible. 
\end{theorem}
\begin{corollary}
  $\mathbb{F}[x]/(f)$ is a field if and only if $f$ is irreducible. 
\end{corollary}
